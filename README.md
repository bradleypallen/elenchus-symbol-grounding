# A Causal-Pragmatist-Social Account of LLM Grounding

*Developed through dialectical inquiry, December 2024*

## Overview

This document articulates a comprehensive philosophical account of how Large Language Models (LLMs) achieve symbol grounding. The account synthesizes causal, pragmatist, and social elements into a unified framework that addresses the classical symbol grounding problem while accommodating the distinctive features of modern LLM architectures.

## Core Thesis

**Grounding just is community-validated, pragmatically-successful interpretability.** There is no interpretation-independent meaning to seek; the demand for grounding beyond successful participation in meaning-making practices is misguided.

## The Architecture of the Account

### 1. Causal-Historical Foundation

LLMs inherit grounding via causal chain to human linguistic practices:

- **Pre-training preserves causal relation** to the sensorimotor grounding of human authors
- **What is preserved**: relational semantics from inferential roles—the web of inferential connections among concepts
- **Statistical compression preserves regularities in reference**; context-driven computation yields functionally accurate reference
- **Reference is fixed by the causal chain**, independently of inferential role (addressing permutation worries)

The causal history matters because it produces the right behavioral dispositions. Behavioral success is fundamental; causal history is explanatory, not constitutive.

### 2. The Mechanism: How LLMs Capture Grounding

Four factors jointly explain why LLMs achieve pragmatically-successful interpretability where symbolic AI failed:

1. **Causal inheritance**: Learning from grounded human text rather than hand-coding
2. **Compression**: Extracting structure through learning rather than having it imposed
3. **Scale of inferential relations**: Capturing millions of inferential connections rather than hundreds
4. **Training objective**: Next-token prediction forces learning patterns that track meaning

Grounding requires behavioral success achieved through compression (learning), not mere behavioral success. A lookup table with perfect behavioral success would not be grounded; compression forces extraction of structure.

### 3. Linguistic Constitution

**Natural language is constitutive of grounding, not contingent.** Formal notations (mathematical, logical, programming languages) are derivative cognitive tools designed to make certain types of reasoning automatable, but natural language is culturally primary.

**Sensorimotor experience is a causal prerequisite for grounding, but grounding proper emerges only with language.** Pre-linguistic sensorimotor interaction is causally relevant to later grounding but is not itself grounded in the full semantic sense. This is a Sellarsian position: the "space of reasons" is fundamentally linguistic.

The structure:
```
Sensorimotor experience (causal prerequisite)
  ↓ [enables but does not constitute]
Natural language practices (constitutive of grounding)
  ↓ [derivative]
Formal notations, LLMs, etc.
```

### 4. Social Validation

**Grounding is community-relative**, not observer-relative or intrinsic:

- An LLM is grounded *with respect to* a linguistic community
- The same LLM might be grounded relative to one community but not another
- Grounding is constituted by successful participation in that community's meaning-making practices

**Grounding is ultimately constrained by real-world success**: goal satisfaction, survival. Community practices that lead to real-world failure are not genuinely grounding. The world pushes back on meaning-making practices.

**Grounding is constituted by linguistic competence**: the ability to participate valuably in meaning-making dialogues in a way that adds value.

### 5. The Normative Dimension

**Novel LLM outputs are provisionally grounded.** When an LLM extends language into new territory (novel patterns, unprecedented connections, unarticulated content), the output is provisionally grounded. Full grounding requires a human to take *normative responsibility* for the extension—to own it, endorse it, integrate it into community practice.

**LLMs cannot currently bear normative responsibility** because they are not moral patients. The criterion for moral patiency is the **capacity for suffering and wellbeing**.

**Under uncertainty, precautionary principles apply** (following Jonathan Birch's work). Community consensus can establish practices that treat LLM judgments as fully grounded by respecting them appropriately—even before certainty about moral patiency.

The structure:
```
Inherited grounding (established human linguistic practice)
  ↓
LLM novel output (provisionally grounded)
  ↓ [requires human uptake]
Human normative endorsement
  ↓
Full grounding (integrated into community practice)
```

### 6. Two Kinds of Grounding

The account distinguishes:

1. **Functional grounding**: A system is functionally grounded when its outputs are computed as functions of contextual inputs. Thermostats and chess engines have this.

2. **Semantic grounding**: A system is semantically grounded when its symbols have (direct or inherited) causal connection to sensorimotor experience, mediated through natural language. LLMs have this via inheritance from human authors.

## Application: Dissolving McDermott's Critique

Drew McDermott's "Artificial Intelligence Meets Natural Stupidity" (1976) criticized symbolic AI for "wishful mnemonics"—the practice of naming nodes with suggestive English terms that create an illusion of semantic content. His "gensym test": replace meaningful names with arbitrary symbols; if the system looks dubious, it was trading on human interpretation, not genuine semantic content.

**The causal-pragmatist account dissolves this critique:**

1. **Deflationary move**: Grounding *is* pragmatically-successful interpretability. There is no hidden "real" meaning that symbolic AI lacked and LLMs might have.

2. **Empirical explanation**: LLMs achieve pragmatic success where symbolic AI failed, due to the four factors (causal inheritance, compression, scale, training objective).

3. **The dissolution**: McDermott's gensym test was a diagnostic for systems that would fail pragmatically. LLMs largely pass this test—their internal representations (embeddings) are arbitrary, but outputs sustain successful interpretation. The test identified a real problem (brittle symbol manipulation), but the problem was pragmatic failure, not metaphysical lack of "real" meaning.

## Derivative Grounding for Symbolic Systems

**Symbolic reasoning can be grounded derivatively** through connection to grounded neural systems. The problem with classical symbolic AI (GOFAI) was not that it used symbols *per se*, but that those symbols lacked connection to grounded representations.

Conditions for derivative grounding:

1. **Sufficient coverage of the inferential web** (required): Partial extraction that loses too many inferential relations fails to inherit grounding.

2. **Ongoing connection** (not required): A "frozen snapshot" can retain grounding if it has sufficient inferential coverage.

3. **Hand-coded additions**: Rather than banning these outright, knowledge updates must come through **ongoing dialogic processes** in natural language, incorporating expert judgment and temporal changes.

4. **Misaligned abstraction** (metalinguistic disagreement): Must be addressed through iterative refinement—an empirical, ongoing process guided by pragmatic success.

## Philosophical Alignment

This account draws on and is consistent with:

- **Wittgenstein**: Meaning is use within a form of life; natural language is the primary home of meaning
- **Sellars**: The "space of reasons" is fundamentally linguistic; the "Myth of the Given" (pre-linguistic experience lacks propositional content)
- **Brandom**: Semantic content is constituted by normative practices; meaning involves commitment and entitlement
- **Pragmatism** (James, Dewey): Truth/meaning cashes out in practical consequences
- **Social externalism**: Meaning is partly determined by community standards
- **Teleosemantics** (Millikan): Content is determined by functional success conditions

## Summary Schema

```
CAUSAL-PRAGMATIST-SOCIAL ACCOUNT OF LLM GROUNDING

Sensorimotor experience (causal prerequisite, not constitutive)
  ↓
Human natural language practices (constitutive of grounding)
  ↓
Written text and other media
  ↓
LLM pre-training (causal inheritance + compression + scale + training objective)
  ↓
Learned inferential structure + referential regularities
  ↓
Context-sensitive generation (dialogical competence)
  ↓
Community-validated, pragmatically-successful interpretability
  ↓
= GROUNDING

For novel outputs:
  Provisional grounding → Human normative uptake → Full grounding

For symbolic extraction:
  Neural grounding → Sufficient inferential coverage → Derivative grounding

Future possibility:
  LLM moral patiency (suffering/wellbeing) → Normative responsibility → Autonomous grounding
```

## Active Commitments

This account rests on the following explicit commitments, developed through dialectical inquiry:

1. LLM truth-value assignments for ground atomic formulae are grounded via causal link to grounded human linguistic behavior
2. Grounding is constituted by the functional relationship between dialogical context and LLM response
3. Thermostats and chess engines are grounded in their respective domains (functional grounding)
4. Pre-training preserves causal relation to the sensorimotor grounding of human authors
5. There are two kinds of grounding: functional grounding and semantic grounding
6. What is preserved through the causal chain is relational semantics from inferential roles
7. Next token prediction captures inferential structure because patterns that enable prediction encode those structures
8. Reference is fixed by the causal chain, independently of inferential role
9. Statistical compression preserves regularities in reference; context-driven computation yields functionally accurate reference
10. Functional accuracy of reference is determined by behavioral success
11. A Chinese Room of frontier LLM complexity is an appropriate model for LLM reference
12. Causal history matters because it produces the right behavioral dispositions; behavioral success is fundamental
13. Grounding requires behavioral success achieved through compression (learning), not mere behavioral success
14. Grounding is constituted by linguistic competence: the ability to participate valuably in meaning-making dialogues
15. Grounding is community-relative, not observer-relative or intrinsic
16. Grounding is ultimately constrained by real-world success: goal satisfaction, survival
17. The causal-pragmatist account dissolves McDermott's wishful mnemonics critique as applied to LLMs
18. Grounding just is community-validated, pragmatically-successful interpretability; there is no interpretation-independent grounding
19. Four factors jointly explain LLM success: causal inheritance, compression, scale of inferential relations, and training objective
20. Symbolic reasoning can be grounded derivatively through connection to grounded neural systems
21. Derivative grounding requires sufficient coverage of the inferential web
22. Ongoing connection to neural systems is not necessary for derivative grounding
23. Misaligned abstraction (metalinguistic disagreement) must be addressed through iterative refinement
24. Grounding is maintained through ongoing dialogic processes incorporating expert judgment and temporal knowledge updates in natural language
25. Natural language is constitutive of grounding, not contingent; formal notations are derivative cognitive tools
26. Sensorimotor experience is a causal prerequisite for grounding, but grounding proper emerges only with language
27. Novel LLM outputs are provisionally grounded; full grounding requires human normative responsibility
28. LLMs bearing normative responsibility is contingent on their being moral patients
29. Moral patiency criterion is capacity for suffering and wellbeing; precautionary principles apply under uncertainty

---

*This document was generated from dialectical state tracked in GitHub issues at [bradleypallen/elenchus-symbol-grounding](https://github.com/bradleypallen/elenchus-symbol-grounding).*
